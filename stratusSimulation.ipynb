{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Processing Machine events and task events data for data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Task Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve task runtime:\n",
    "    1. Idenitfy submissions and completetions of each job, removing duplicate entries\n",
    "    2. Calculate the duration between the submission and completion timestamps to determine how long each job ran\n",
    "\n",
    "Note:\n",
    "For each job id, the runtime is the timestamp of event type = 4 (finished) - event type = 0 (submitted)\n",
    "Also, since timestamp is in millisecond, get the runtime in seconds (round off)\n",
    "Laslt, only store tasks with both finished and submitted ids with their actual runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum timestamp: 5611.0\n",
      "Found 38362 tasks with complete runtime data\n",
      "\n",
      "Sample of task runtimes:\n",
      "       job_ID  task_index  CPU_request  memory_request  timestamp  runtime\n",
      "0  6250345153         878      0.06873        0.011930      604.0   2368.0\n",
      "1  6251639646           0      0.06250        0.015900      604.0     71.0\n",
      "2  6251668759           0      0.06250        0.004662      612.0     50.0\n",
      "3  6250345153         822      0.06873        0.011930      614.0   2155.0\n",
      "4  6251668917           0      0.03125        0.015900      617.0     36.0\n"
     ]
    }
   ],
   "source": [
    "from DataPrep.task_runtime_calculator import calculate_task_runtimes\n",
    "\n",
    "task_runtimes, maximumStamp = calculate_task_runtimes()\n",
    "\n",
    "# Drop rows with missing data (if any)\n",
    "task_runtimes = task_runtimes.dropna(subset=['task_index', 'CPU_request', 'memory_request', 'timestamp', 'runtime'])\n",
    "\n",
    "# Print results\n",
    "print(f\"Maximum timestamp: {maximumStamp}\")\n",
    "print(f\"Found {len(task_runtimes)} tasks with complete runtime data\")\n",
    "print(\"\\nSample of task runtimes:\")\n",
    "print(task_runtimes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Available Instance Types and Their Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Instance Types and Their Normalized Prices:\n",
      "============================================================\n",
      "    capacity_CPU  capacity_memory  normalized_price\n",
      "10          1.00          1.00000          1.000000\n",
      "9           1.00          0.50000          0.940904\n",
      "8           0.50          0.96780          0.555290\n",
      "7           0.50          0.74900          0.529430\n",
      "6           0.50          0.49950          0.499941\n",
      "5           0.50          0.24930          0.470369\n",
      "4           0.50          0.12410          0.455571\n",
      "3           0.50          0.06158          0.448182\n",
      "2           0.50          0.03085          0.444550\n",
      "1           0.25          0.24980          0.249976\n"
     ]
    }
   ],
   "source": [
    "from DataPrep.instance_retriever import get_instance_types_and_prices\n",
    "\n",
    "instance_types = get_instance_types_and_prices()\n",
    "sorted_instance_types = instance_types.sort_values(\n",
    "    by=[\"capacity_CPU\", \"capacity_memory\"], ascending=[False, False]\n",
    ")\n",
    "instance_types = sorted_instance_types\n",
    "print(\"Available Instance Types and Their Normalized Prices:\")\n",
    "print(\"=\" * 60)\n",
    "print(instance_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratus Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try simulating Stratus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances used: 4\n",
      "Price of simulation: 6039.764862\n",
      "Average CPU utilization: 30.98%\n",
      "Average memory utilization: 33.13%\n"
     ]
    }
   ],
   "source": [
    "from schedulers.stratus_scheduler import StratusScheduler\n",
    "\n",
    "scheduler = StratusScheduler(instance_types)\n",
    "tasks_by_timestamp = task_runtimes.groupby('timestamp')\n",
    "\n",
    "total_cpu_utilization = 0\n",
    "total_memory_utilization = 0\n",
    "timestamp_count = 0\n",
    "\n",
    "# Iterate over each timestamp and its corresponding tasks\n",
    "for timestamp, tasks in tasks_by_timestamp:\n",
    "\n",
    "    if timestamp >= 700:\n",
    "        break\n",
    "    \n",
    "    # Free expired tasks and instances\n",
    "    scheduler.free_tasks_and_instances(timestamp)\n",
    "    \n",
    "    # Pass tasks for the current timestamp to the packer\n",
    "    scheduler.packer(tasks)\n",
    "\n",
    "    # Accumulate CPU and memory utilization\n",
    "    total_cpu_utilization += scheduler.cpu_utilization\n",
    "    total_memory_utilization += scheduler.memory_utilization\n",
    "    timestamp_count += 1\n",
    "\n",
    "# Calculate average CPU and memory utilization\n",
    "average_cpu_utilization = total_cpu_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "average_memory_utilization = total_memory_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "\n",
    "# Check results\n",
    "print(\"Number of instances used: \" + str(scheduler.instance_counter))\n",
    "print(\"Price of simulation: \" + str(scheduler.price_counter))\n",
    "print(\"Average CPU utilization: \" + str(round(average_cpu_utilization, 2)) + \"%\")\n",
    "print(\"Average memory utilization: \" + str(round(average_memory_utilization, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Fit Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try First Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances used: 3\n",
      "Price of simulation: 2740.7823280000002\n",
      "Average CPU utilization: 39.73%\n",
      "Average memory utilization: 39.39%\n"
     ]
    }
   ],
   "source": [
    "from schedulers.first_fit_scheduler import FirstFitScheduler\n",
    "\n",
    "scheduler = FirstFitScheduler(instance_types)\n",
    "tasks_by_timestamp = task_runtimes.groupby('timestamp')\n",
    "\n",
    "\n",
    "total_cpu_utilization = 0\n",
    "total_memory_utilization = 0\n",
    "timestamp_count = 0\n",
    "\n",
    "# Iterate over each timestamp and its corresponding tasks\n",
    "for timestamp, tasks in tasks_by_timestamp:\n",
    "    if timestamp >= 700:\n",
    "        break\n",
    "    \n",
    "    # Free expired tasks and instances\n",
    "    scheduler.free_tasks_and_instances(timestamp)\n",
    "    \n",
    "    # Pass tasks for the current timestamp to the packer\n",
    "    scheduler.first_fit_scheduler(tasks)\n",
    "    \n",
    "    total_cpu_utilization += scheduler.cpu_utilization\n",
    "    total_memory_utilization += scheduler.memory_utilization\n",
    "    timestamp_count += 1\n",
    "\n",
    "# Calculate average CPU and memory utilization\n",
    "average_cpu_utilization = total_cpu_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "average_memory_utilization = total_memory_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "\n",
    "# Check results\n",
    "print(\"Number of instances used: \" + str(scheduler.instance_counter))\n",
    "print(\"Price of simulation: \" + str(scheduler.price_counter))\n",
    "print(\"Average CPU utilization: \" + str(round(average_cpu_utilization, 2)) + \"%\")\n",
    "print(\"Average memory utilization: \" + str(round(average_memory_utilization, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Fit Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Best Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances used: 1\n",
      "Price of simulation: 4585.0\n",
      "Average CPU utilization: 32.62%\n",
      "Average memory utilization: 12.92%\n"
     ]
    }
   ],
   "source": [
    "from schedulers.best_fit_scheduler import BestFitScheduler\n",
    "\n",
    "scheduler = BestFitScheduler(instance_types)\n",
    "tasks_by_timestamp = task_runtimes.groupby('timestamp')\n",
    "\n",
    "total_cpu_utilization = 0\n",
    "total_memory_utilization = 0\n",
    "timestamp_count = 0\n",
    "\n",
    "# Iterate over each timestamp and its corresponding tasks\n",
    "for timestamp, tasks in tasks_by_timestamp:\n",
    "\n",
    "    if timestamp >= 700:\n",
    "        break\n",
    "    \n",
    "    # Free expired tasks and instances\n",
    "    scheduler.free_tasks_and_instances(timestamp)\n",
    "    \n",
    "    # Pass tasks for the current timestamp to the packer\n",
    "    scheduler.best_fit_scheduler(tasks)\n",
    "\n",
    "    total_cpu_utilization += scheduler.cpu_utilization\n",
    "    total_memory_utilization += scheduler.memory_utilization\n",
    "    timestamp_count += 1\n",
    "\n",
    "# Calculate average CPU and memory utilization\n",
    "average_cpu_utilization = total_cpu_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "average_memory_utilization = total_memory_utilization / timestamp_count if timestamp_count > 0 else 0\n",
    "\n",
    "# Check results\n",
    "print(\"Number of instances used: \" + str(scheduler.instance_counter))\n",
    "print(\"Price of simulation: \" + str(scheduler.price_counter))\n",
    "print(\"Average CPU utilization: \" + str(round(average_cpu_utilization, 2)) + \"%\")\n",
    "print(\"Average memory utilization: \" + str(round(average_memory_utilization, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing all 3 incremently based on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratus_scheduler = StratusScheduler(instance_types)\n",
    "firstfit_scheduler = FirstFitScheduler(instance_types)\n",
    "bestfit_scheduler = BestFitScheduler(instance_types)\n",
    "\n",
    "\n",
    "timestamp_points = []\n",
    "\n",
    "# Stratus data\n",
    "stratus_cpu_utilization = []\n",
    "stratus_memory_utilization = []\n",
    "stratus_price = []\n",
    "stratus_instances = []\n",
    "\n",
    "# FirstFit data\n",
    "firstfit_cpu_utilization = []\n",
    "firstfit_memory_utilization = []\n",
    "firstfit_price = []\n",
    "firstfit_instances = []\n",
    "\n",
    "# BestFit data\n",
    "bestfit_cpu_utilization = []\n",
    "bestfit_memory_utilization = []\n",
    "bestfit_price = []\n",
    "bestfit_instances = []\n",
    "\n",
    "tasks_by_timestamp = task_runtimes.groupby('timestamp')\n",
    "\n",
    "# Iterate over each timestamp and its corresponding tasks\n",
    "for timestamp, tasks in tasks_by_timestamp:\n",
    "    \n",
    "    timestamp_points.append(timestamp)\n",
    "\n",
    "    # Free expired tasks and instances\n",
    "    stratus_scheduler.free_tasks_and_instances(timestamp)\n",
    "    firstfit_scheduler.free_tasks_and_instances(timestamp)\n",
    "    bestfit_scheduler.free_tasks_and_instances(timestamp)\n",
    "\n",
    "    # Pass tasks for the current timestamp to the packer\n",
    "    stratus_scheduler.packer(tasks)\n",
    "    firstfit_scheduler.first_fit_scheduler(tasks)\n",
    "    bestfit_scheduler.best_fit_scheduler(tasks)\n",
    "\n",
    "    # Add new data\n",
    "    stratus_cpu_utilization.append(stratus_scheduler.cpu_utilization)\n",
    "    stratus_memory_utilization.append(stratus_scheduler.memory_utilization)\n",
    "    stratus_price.append(stratus_scheduler.price_counter)\n",
    "    stratus_instances.append(stratus_scheduler.instance_counter)\n",
    "\n",
    "    firstfit_cpu_utilization.append(firstfit_scheduler.cpu_utilization)\n",
    "    firstfit_memory_utilization.append(firstfit_scheduler.memory_utilization)\n",
    "    firstfit_price.append(firstfit_scheduler.price_counter)\n",
    "    firstfit_instances.append(firstfit_scheduler.instance_counter)\n",
    "\n",
    "    bestfit_cpu_utilization.append(bestfit_scheduler.cpu_utilization)\n",
    "    bestfit_memory_utilization.append(bestfit_scheduler.memory_utilization)\n",
    "    bestfit_price.append(bestfit_scheduler.price_counter)\n",
    "    bestfit_instances.append(bestfit_scheduler.instance_counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'timestamp_points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the total price for each scheduler against the timestamp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtimestamp_points\u001b[49m, stratus_price, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStratus Scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(timestamp_points, firstfit_price, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirstFit Scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(timestamp_points, bestfit_price, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBestFit Scheduler\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-.\u001b[39m\u001b[38;5;124m'\u001b[39m, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'timestamp_points' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Plot the total price for each scheduler against the timestamp\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamp_points, stratus_price, label='Stratus Scheduler', linestyle='-', marker='o')\n",
    "plt.plot(timestamp_points, firstfit_price, label='FirstFit Scheduler', linestyle='--', marker='s')\n",
    "plt.plot(timestamp_points, bestfit_price, label='BestFit Scheduler', linestyle='-.', marker='^')\n",
    "plt.xlabel('Timestamp', fontsize=12)\n",
    "plt.ylabel('Total Price', fontsize=12)\n",
    "plt.title('Total Price vs Timestamp for Different Schedulers', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cumulative average utilization for each scheduler\n",
    "stratus_avg_cpu_utilization = np.cumsum(stratus_cpu_utilization) / np.arange(1, len(stratus_cpu_utilization) + 1)\n",
    "firstfit_avg_cpu_utilization = np.cumsum(firstfit_cpu_utilization) / np.arange(1, len(firstfit_cpu_utilization) + 1)\n",
    "bestfit_avg_cpu_utilization = np.cumsum(bestfit_cpu_utilization) / np.arange(1, len(bestfit_cpu_utilization) + 1)\n",
    "# Plot CPU utilization against timestamp for the three schedulers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamp_points, stratus_avg_cpu_utilization, label=\"Stratus Scheduler\", linestyle='-', marker='o')\n",
    "plt.plot(timestamp_points, firstfit_avg_cpu_utilization, label=\"FirstFit Scheduler\", linestyle='--', marker='s')\n",
    "plt.plot(timestamp_points, bestfit_avg_cpu_utilization, label=\"BestFit Scheduler\", linestyle='-.', marker='^')\n",
    "plt.title(\"Average CPU Utilization Over Time\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Average CPU Utilization\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate cumulative average utilization for each scheduler\n",
    "stratus_avg_mem_utilization = np.cumsum(stratus_memory_utilization) / np.arange(1, len(stratus_memory_utilization) + 1)\n",
    "firstfit_avg_mem_utilization = np.cumsum(firstfit_memory_utilization) / np.arange(1, len(firstfit_memory_utilization) + 1)\n",
    "bestfit_avg_mem_utilization = np.cumsum(bestfit_memory_utilization) / np.arange(1, len(bestfit_memory_utilization) + 1)\n",
    "# Plot CPU utilization against timestamp for the three schedulers\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamp_points, stratus_avg_mem_utilization, label=\"Stratus Scheduler\", linestyle='-', marker='o')\n",
    "plt.plot(timestamp_points, firstfit_avg_mem_utilization, label=\"FirstFit Scheduler\", linestyle='--', marker='s')\n",
    "plt.plot(timestamp_points, bestfit_avg_mem_utilization, label=\"BestFit Scheduler\", linestyle='-.', marker='^')\n",
    "plt.title(\"Average Memory Utilization Over Time\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Average Memory Utilization\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the total instances for each scheduler against the timestamp\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(timestamp_points, stratus_instances, label='Stratus Scheduler', linestyle='-', marker='o')\n",
    "plt.plot(timestamp_points, firstfit_instances, label='FirstFit Scheduler', linestyle='--', marker='s')\n",
    "plt.plot(timestamp_points, bestfit_instances, label='BestFit Scheduler', linestyle='-.', marker='^')\n",
    "plt.xlabel('Timestamp', fontsize=12)\n",
    "plt.ylabel('Total Active Instances', fontsize=12)\n",
    "plt.title('Total Active Instances vs Timestamp for Different Schedulers', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
